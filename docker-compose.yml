services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.9.4
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:8.1.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:9093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:9092,CONTROLLER://kafka:9093'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'

  postgres:
    image: postgres:17-alpine
    container_name: postgres
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: crypto_data
    volumes:
      - ./postgres/init:/docker-entrypoint-initdb.d
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    depends_on:
      - postgres
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    ports:
      - "5050:80"
    volumes:
      - pgadmin-data:/var/lib/pgadmin
  
  producer:
    build: ./producer
    container_name: producer
    depends_on:
      - kafka
    command: >
      sh -c "
        echo 'Waiting for Kafka to be ready...' &&
        while ! nc -z kafka 9092; do
          sleep 0.5;
        done;
        echo 'Kafka is ready!' &&
        python producer.py
      "
    environment:
      EXCHANGE_WS_URL: wss://stream.binance.com:9443/ws
      CRYPTO_PAIR: btcusdt
      KAFKA_BROKER_URL: kafka:9092
      KAFKA_TOPIC: raw_trades
    volumes:
      - ./producer:/app

  spark-master:
    build: ./spark_processor
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark_processor:/opt/spark/app
    environment:
      - SPARK_NO_DAEMONIZE=true

  spark-worker:
    build: ./spark_processor
    container_name: spark-worker
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1g
    volumes:
      - ./spark_processor:/opt/spark/app

  spark-submit:
    build: ./spark_processor
    container_name: spark-submit
    depends_on:
      - spark-master
      - kafka
      - postgres
    environment:
      - KAFKA_BROKER_URL=kafka:9092
      - KAFKA_TOPIC=raw_trades
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=crypto_data
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - SPARK_MASTER_URL=spark://spark-master:7077
      - CHECKPOINT_LOCATION=/opt/spark/app/checkpoint
    command: [
      "/opt/spark/bin/spark-submit",
      "--master", "spark://spark-master:7077",
      "--jars", 
      "/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,
      /opt/spark/jars/kafka-clients-3.7.0.jar,/opt/spark/jars/postgresql-42.7.3.jar,
      /opt/spark/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,
      /opt/spark/jars/kafka_2.12-3.7.0.jar,
      /opt/spark/jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,
      /opt/spark/jars/commons-pool2-2.12.0.jar",
      "/opt/spark/app/processor.py"
    ]

volumes:
  postgres-data:
  pgadmin-data: